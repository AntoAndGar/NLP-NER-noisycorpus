{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from a personal database of code, frankly I don't remember the reference\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from data_loading import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from rich.progress import track\n",
    "from vocabulary import Vocabulary\n",
    "from ner_pretrain_noisycorpus import NERv1_PRE\n",
    "from gensim.models import KeyedVectors\n",
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from typing import List, Any, Dict\n",
    "from configuration import TRAINING_PATH, DEV_PATH, TEST_PATH, MODEL_PATH, UNK_WORD, TAG_DICT, PRETRAINED_PATH\n",
    "from configuration import EMBEDDING_SIZE, HIDDEN_SIZE, BATCH_SIZE, EPOCHS, NUM_LAYERS, BIDIRECTIONAL, PRETRAINED\n",
    "\n",
    "from IPython.display import HTML, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cstr(s, color='black'):\n",
    "    if s == ' ':\n",
    "        return f'<text style=color:#000;padding-left:10px;background-color:{color}> </text>'\n",
    "    else:\n",
    "        return f'<text style=color:#000;background-color:{color}>{s} </text>'\n",
    "\n",
    "# print html\n",
    "def _print_color(t):\n",
    "    display(HTML(''.join([_cstr(ti, color=ci) for ti, ci in t])))\n",
    "\n",
    "# get appropriate color for value\n",
    "def _get_clr(value):\n",
    "    colors = ('#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8',\n",
    "            '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
    "            '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
    "            '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e')\n",
    "    value = int((value * 100) / 5)\n",
    "    if value == len(colors): value -= 1  # fixing bugs...\n",
    "    return colors[value]\n",
    "\n",
    "def print_colourbar():\n",
    "    color_range = torch.linspace(-2.5, 2.5, 20)\n",
    "    to_print = [(f'{x:.2f}', _get_clr((x+2.5)/5)) for x in color_range]\n",
    "    _print_color(to_print)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<text style=color:#000;background-color:#85c2e1>-2.50 </text><text style=color:#000;background-color:#89c4e2>-2.24 </text><text style=color:#000;background-color:#95cae5>-1.97 </text><text style=color:#000;background-color:#99cce6>-1.71 </text><text style=color:#000;background-color:#a1d0e8>-1.45 </text><text style=color:#000;background-color:#b2d9ec>-1.18 </text><text style=color:#000;background-color:#baddee>-0.92 </text><text style=color:#000;background-color:#c2e1f0>-0.66 </text><text style=color:#000;background-color:#eff7fb>-0.39 </text><text style=color:#000;background-color:#f9e8e8>-0.13 </text><text style=color:#000;background-color:#f9e8e8>0.13 </text><text style=color:#000;background-color:#f9d4d4>0.39 </text><text style=color:#000;background-color:#f9bdbd>0.66 </text><text style=color:#000;background-color:#f8a8a8>0.92 </text><text style=color:#000;background-color:#f68f8f>1.18 </text><text style=color:#000;background-color:#f47676>1.45 </text><text style=color:#000;background-color:#f45f5f>1.71 </text><text style=color:#000;background-color:#f34343>1.97 </text><text style=color:#000;background-color:#f33b3b>2.24 </text><text style=color:#000;background-color:#f42e2e>2.50 </text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_colourbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<text style=color:#000;background-color:#85c2e1>O </text><text style=color:#000;background-color:#c2e1f0>B-PER </text><text style=color:#000;background-color:#95cae5>I-PER </text><text style=color:#000;background-color:#f8a8a8>B-LOC </text><text style=color:#000;background-color:#f42e2e>I-LOC </text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_values(output_values, result_list):\n",
    "    text_colours = []\n",
    "    for i in range(len(output_values)):\n",
    "        text = (result_list[i], _get_clr(output_values[i]))\n",
    "        text_colours.append(text)\n",
    "    _print_color(text_colours)\n",
    "\n",
    "def plot_state(data, state, b, decoder):\n",
    "    actual_data = decoder(data[b, :, :].numpy())\n",
    "    seq_len = len(actual_data)\n",
    "    seq_len_w_pad = len(state)\n",
    "    for s in range(state.size(2)):\n",
    "        states = torch.sigmoid(state[:, b, s])\n",
    "        visualize_values(states[seq_len_w_pad - seq_len:], list(actual_data))\n",
    "\n",
    "visualize_values([-1.00, -0.66, 0.13, 0.66, 1.00], ['O', 'B-PER', 'I-PER', 'B-LOC', 'I-LOC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ant/Documents/nlp2022-hw1/hw1\n",
      "/home/ant/Documents/nlp2022-hw1\n",
      "Loaded pretrained embeddings at model/glove_pretrained_300\n",
      "Model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_122243/4198494113.py:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  visualize_values(torch.nn.functional.softmax(elem),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:#000;background-color:#85c2e1>B-CORP </text><text style=color:#000;background-color:#a1d0e8>B-CW </text><text style=color:#000;background-color:#85c2e1>B-GRP </text><text style=color:#000;background-color:#85c2e1>B-LOC </text><text style=color:#000;background-color:#99cce6>B-PER </text><text style=color:#000;background-color:#c2e1f0>B-PROD </text><text style=color:#000;background-color:#85c2e1>I-CORP </text><text style=color:#000;background-color:#85c2e1>I-CW </text><text style=color:#000;background-color:#85c2e1>I-GRP </text><text style=color:#000;background-color:#85c2e1>I-LOC </text><text style=color:#000;background-color:#85c2e1>I-PER </text><text style=color:#000;background-color:#85c2e1>I-PROD </text><text style=color:#000;background-color:#99cce6>O </text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<text style=color:#000;background-color:#85c2e1>B-CORP </text><text style=color:#000;background-color:#85c2e1>B-CW </text><text style=color:#000;background-color:#85c2e1>B-GRP </text><text style=color:#000;background-color:#85c2e1>B-LOC </text><text style=color:#000;background-color:#85c2e1>B-PER </text><text style=color:#000;background-color:#85c2e1>B-PROD </text><text style=color:#000;background-color:#85c2e1>I-CORP </text><text style=color:#000;background-color:#eff7fb>I-CW </text><text style=color:#000;background-color:#85c2e1>I-GRP </text><text style=color:#000;background-color:#85c2e1>I-LOC </text><text style=color:#000;background-color:#99cce6>I-PER </text><text style=color:#000;background-color:#a1d0e8>I-PROD </text><text style=color:#000;background-color:#99cce6>O </text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I- tag with different tag\n",
      "[['B-PROD', 'I-PROD']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import torch.nn\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "module_path1 = os.path.abspath('/'.join(module_path.split('/')[:-1]))\n",
    "if module_path1 not in sys.path:\n",
    "    sys.path.append(module_path1+\"/model\")\n",
    "\n",
    "print(module_path)\n",
    "print(module_path1)\n",
    "\n",
    "class StudentModel():\n",
    "\n",
    "    # STUDENT: construct here your model\n",
    "    # this class should be loading your weights and vocabulary\n",
    "\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.dataset = DatasetNER(module_path1+'/'+TRAINING_PATH, verbose=False)\n",
    "        self.weights = self.init_weights(PRETRAINED)\n",
    "        self.vocab = self.init_vocab(self.dataset, self.weights)\n",
    "        self.tags = TAG_DICT\n",
    "        self.emb_size = EMBEDDING_SIZE\n",
    "        self.hidden_size = HIDDEN_SIZE\n",
    "        self.num_layers = NUM_LAYERS\n",
    "        self.bidirectional = BIDIRECTIONAL\n",
    "        self.num_classes = len(self.tags)\n",
    "        self.model = NERv1_PRE(len(self.vocab), self.emb_size, self.hidden_size, self.num_layers, self.num_classes, self.bidirectional, device, self.weights)\n",
    "        print(\"Model loaded\")\n",
    "\n",
    "    def init_weights(self, pretrained = False):\n",
    "        if pretrained:\n",
    "            weights = KeyedVectors.load(module_path1+'/'+PRETRAINED_PATH)\n",
    "            print(f'Loaded pretrained embeddings at {PRETRAINED_PATH}')\n",
    "            return weights\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def init_vocab(self, dataset, weights=None):\n",
    "        if weights is not None:\n",
    "            tokens = [weights.index_to_key[i] for i in range(weights.vectors.shape[0])]\n",
    "            return Vocabulary(tokens, min_freq=1, unk_token=UNK_WORD)\n",
    "        else:\n",
    "            return Vocabulary(dataset.tokens, min_freq=1, unk_token=UNK_WORD)\n",
    "\n",
    "    def expert_postprocess(self, pred_lbl):\n",
    "        for sentence in pred_lbl:\n",
    "            for i, token in enumerate(sentence):\n",
    "                if token.startswith(\"I-\"):\n",
    "                    if i == 0:\n",
    "                        sentence[i] = \"B-\" + token[2:]\n",
    "                        print(\"I- tag at the beginning of sentence\")\n",
    "                    elif sentence[i-1] == \"O\":\n",
    "                        sentence[i] = \"B-\" + token[2:]\n",
    "                        print(\"I- tag without B- tag\")\n",
    "                    elif (sentence[i-1].startswith(\"I-\") or sentence[i-1].startswith(\"B-\")) and sentence[i-1][2:] != sentence[i][2:]:\n",
    "                        sentence[i] = \"I-\" + sentence[i-1][2:]\n",
    "                        print(\"I- tag with different tag\")\n",
    "\n",
    "    def predict(self, tokens: List[List[str]]) -> List[List[str]]:\n",
    "        # STUDENT: implement here your predict function\n",
    "        # remember to respect the same order of tokens!\n",
    "        self.model.load_state_dict(torch.load(module_path1+'/'+MODEL_PATH, map_location=torch.device(self.device)))\n",
    "        self.model.eval()\n",
    "        sentences = []\n",
    "        offsets = []\n",
    "        for list in tokens:\n",
    "            index_phrase = torch.tensor(Vocabulary.word_to_index(list, self.vocab), dtype=torch.int64)\n",
    "            sentences.append(index_phrase)\n",
    "            offsets.append(index_phrase.size(0))\n",
    "        sentences = torch.cat(sentences)\n",
    "        predicted_indexes = self.model(sentences)\n",
    "        predicted_labels = [Vocabulary.index_to_tags(phrase.tolist(), self.tags) for phrase in torch.split(predicted_indexes.argmax(1), offsets)]\n",
    "        for elem in predicted_indexes:\n",
    "            visualize_values(torch.nn.functional.softmax(elem), \n",
    "            [\"B-CORP\", \"B-CW\", \"B-GRP\", \"B-LOC\", \"B-PER\", \"B-PROD\", \"I-CORP\", \"I-CW\", \"I-GRP\", \"I-LOC\", \"I-PER\", \"I-PROD\", \"O\"])\n",
    "        self.expert_postprocess(predicted_labels)\n",
    "        return predicted_labels\n",
    "\n",
    "\n",
    "'''     def visualize_values(output_values, result_list):\n",
    "            text_colours = []\n",
    "            for i in range(len(output_values)):\n",
    "                text = (result_list[i], _get_clr(output_values[i]))\n",
    "                text_colours.append(text)\n",
    "            _print_color(text_colours)\n",
    "\n",
    "        def plot_state(data, state, b, decoder):\n",
    "            actual_data = decoder(data[b, :, :].numpy())\n",
    "            seq_len = len(actual_data)\n",
    "            seq_len_w_pad = len(state)\n",
    "            for s in range(state.size(2)):\n",
    "                states = torch.sigmoid(state[:, b, s])\n",
    "                visualise_values(states[seq_len_w_pad - seq_len:], list(actual_data))\n",
    "\n",
    "        def plot_state(list_of_words, cell_state, list_of_13scores):\n",
    "            visualize_values(list_of_words, str_with_color) '''\n",
    "\n",
    "model = StudentModel(\"cpu\")\n",
    "print(model.predict([\"God dog\".split() ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Confusion matrix <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Confusion matrix \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# instances: 12751\n",
      "\t# I-PER: (329, 329)\n",
      "\t# I-LOC: (153, 129)\n",
      "\t# I-CW: (261, 232)\n",
      "\t# O: (10240, 10428)\n",
      "\t# B-CW: (170, 173)\n",
      "\t# B-LOC: (243, 229)\n",
      "\t# B-CORP: (133, 105)\n",
      "\t# I-PROD: (87, 81)\n",
      "\t# I-GRP: (377, 342)\n",
      "\t# B-GRP: (190, 180)\n",
      "\t# I-CORP: (119, 80)\n",
      "\t# B-PER: (300, 305)\n",
      "\t# B-PROD: (149, 138)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def flat_list(l: List[List[Any]]) -> List[Any]:\n",
    "    return [_e for e in l for _e in e]\n",
    "\n",
    "def count(l: List[Any]) -> Dict[Any, int]:\n",
    "    d = {}\n",
    "    for e in l:\n",
    "        d[e] = 1 + d.get(e, 0)\n",
    "    return d\n",
    "\n",
    "def visualize():\n",
    "    valid_dataset = DatasetNER(module_path1+'/'+DEV_PATH, verbose=True) \n",
    "\n",
    "    labels_s = valid_dataset.labels\n",
    "    tokens_s = valid_dataset.tokens\n",
    "\n",
    "    predictions_s = []\n",
    "    batch_size = 32\n",
    "\n",
    "    model = StudentModel(\"cpu\")\n",
    "    for i in track(range(0, len(tokens_s), batch_size), description=\"Visualizing\"):\n",
    "        batch = tokens_s[i : i + batch_size]\n",
    "        predictions_s += model.predict(batch)\n",
    "\n",
    "    flat_labels_s = flat_list(labels_s)\n",
    "    flat_predictions_s = flat_list(predictions_s)\n",
    "\n",
    "    label_distribution = count(flat_labels_s)\n",
    "    pred_distribution = count(flat_predictions_s)\n",
    "\n",
    "    print(f\"# instances: {len(flat_list(labels_s))}\")\n",
    "\n",
    "    keys = set(label_distribution.keys()) | set(pred_distribution.keys())\n",
    "    for k in keys:\n",
    "        print(\n",
    "            f\"\\t# {k}: ({label_distribution.get(k, 0)}, {pred_distribution.get(k, 0)})\"\n",
    "        )\n",
    "\n",
    "visualize()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b8f97d3b9ce63ff98d6d8fc8eaef956e3887110f66e16039732df1be0e30db8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
